{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building the tree1\n",
      "building the tree1\n",
      "building the tree1\n",
      "building the tree1\n",
      "building the tree\n",
      "building the tree\n",
      "building the tree2\n",
      "building the tree1\n",
      "building the tree\n",
      "building the tree\n",
      "building the tree2\n",
      "building the tree2\n",
      "building the tree1\n",
      "building the tree1\n",
      "building the tree\n",
      "building the tree\n",
      "building the tree2\n",
      "building the tree1\n",
      "building the tree\n",
      "building the tree\n",
      "building the tree2\n",
      "building the tree2\n",
      "building the tree2\n",
      "building the tree1\n",
      "building the tree1\n",
      "building the tree1\n",
      "building the tree\n",
      "building the tree\n",
      "building the tree2\n",
      "building the tree1\n",
      "building the tree\n",
      "building the tree\n",
      "building the tree2\n",
      "building the tree2\n",
      "building the tree1\n",
      "building the tree1\n",
      "building the tree\n",
      "building the tree\n",
      "building the tree2\n",
      "building the tree1\n",
      "building the tree\n",
      "building the tree\n",
      "building the tree2\n",
      "building the tree2\n",
      "building the tree2\n",
      "building the tree2\n",
      "Node: Feature 0, Threshold -0.0070094988733019874, Info Gain 0.5496\n",
      "    Node: Feature 1, Threshold 0.7087435181641025, Info Gain 0.4205\n",
      "        Node: Feature 0, Threshold -1.1614933101183216, Info Gain 0.2741\n",
      "            Node: Feature 0, Threshold -1.7662229255323796, Info Gain 0.5750\n",
      "                Leaf: Predict = 5.0\n",
      "                Leaf: Predict = 3.0\n",
      "            Node: Feature 5, Threshold -0.457713717700983, Info Gain 0.2378\n",
      "                Leaf: Predict = 22.0\n",
      "                Leaf: Predict = 11.0\n",
      "        Node: Feature 8, Threshold 1.963337169164356, Info Gain 0.5677\n",
      "            Node: Feature 0, Threshold -1.1065178905352255, Info Gain 0.4583\n",
      "                Leaf: Predict = 17.0\n",
      "                Leaf: Predict = 7.0\n",
      "            Node: Feature 0, Threshold -1.8211983451154758, Info Gain 0.2113\n",
      "                Leaf: Predict = 16.0\n",
      "                Leaf: Predict = 8.0\n",
      "    Node: Feature 0, Threshold 0.5427446969576598, Info Gain 0.2022\n",
      "        Node: Feature 5, Threshold 0.3358962769619819, Info Gain 0.1666\n",
      "            Node: Feature 8, Threshold -0.3329321826682009, Info Gain 0.1459\n",
      "                Leaf: Predict = 12.0\n",
      "                Leaf: Predict = 19.0\n",
      "            Node: Feature 7, Threshold -0.6817232040997633, Info Gain 0.3466\n",
      "                Leaf: Predict = 26.0\n",
      "                Leaf: Predict = 15.0\n",
      "        Node: Feature 8, Threshold -0.31298805918984296, Info Gain 0.1588\n",
      "            Node: Feature 1, Threshold 0.6354561948253825, Info Gain 0.0989\n",
      "                Leaf: Predict = 23.0\n",
      "                Leaf: Predict = 14.0\n",
      "            Node: Feature 0, Threshold 0.9825480536224291, Info Gain 0.0907\n",
      "                Leaf: Predict = 13.0\n",
      "                Leaf: Predict = 18.0\n",
      "Time:  50.40013950000002\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import timeit\n",
    "\n",
    "def data_prepration(name,test_size):\n",
    "\n",
    "    data_file = pd.read_csv(name)\n",
    "    data_file = data_file.sample(frac = 1)\n",
    "\n",
    "    data_file.pop(\"artist_name\")\n",
    "    data_file.pop(\"track_name\")\n",
    "    data_file.pop(\"track_id\")\n",
    "    data_file.pop(\"time_signature\")\n",
    "\n",
    "    genre_data = data_file.pop(\"genre\")\n",
    "\n",
    "    genre_categorical = genre_data.astype('category')\n",
    "    genre_encoded = genre_categorical.cat.codes + 1\n",
    "\n",
    "    data_file = pd.get_dummies(data_file,columns=[\"mode\",\"key\"],dtype=int)\n",
    "    data_file = (data_file - data_file.mean()) / data_file.std()\n",
    "\n",
    "    index = round((1 - test_size) * len(data_file)) \n",
    "    X_Train = data_file[:index]\n",
    "    x_test = data_file[index:]\n",
    "\n",
    "    Y_Train = genre_encoded[:index]\n",
    "    y_test = genre_encoded[index:]\n",
    "\n",
    "\n",
    "    Y_Train=Y_Train.values\n",
    "    y_test = y_test.values\n",
    "    X_Train= X_Train.values\n",
    "    x_test = x_test.values\n",
    "\n",
    "    Y_Train = Y_Train.reshape(-1, 1)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    data_train = np.concatenate([X_Train,Y_Train],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    return data_train,x_test,y_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Node():\n",
    "\n",
    "    def __init__(self, left_child=None, right_child=None, feature_index=None, threshold=None, information_gain=None, predicted_value=None):\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.information_gain = information_gain\n",
    "        self.predicted_value = predicted_value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DecisionTree():\n",
    "\n",
    "    def __init__(self,max_depth):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "\n",
    "\n",
    "    def entropy(self, y_col):\n",
    "\n",
    "        a, occurance = np.unique(y_col, return_counts=True)\n",
    "        pi = occurance / len(y_col)\n",
    "\n",
    "        return -np.sum(pi * np.log2(pi))\n",
    "    \n",
    "        \n",
    "\n",
    "    def Information_Gain(self,parent,left_child,right_child):\n",
    "\n",
    "        parent_entropy = self.entropy(parent)\n",
    "        left_entropy = self.entropy(left_child)\n",
    "        right_entropy = self.entropy(right_child)\n",
    "\n",
    "        left_weight = len(left_child) / len(parent)\n",
    "        right_weight = len(right_child) / len(parent)\n",
    "\n",
    "        return parent_entropy - ((left_entropy*left_weight) + (right_weight * right_entropy))\n",
    "\n",
    "\n",
    "\n",
    "    def split(self,data,feature,treshold):\n",
    "\n",
    "\n",
    "        left = data[data[:,feature] <= treshold]\n",
    "        right = data[data[:,feature] > treshold]\n",
    "\n",
    "        return left,right\n",
    "    \n",
    "\n",
    "\n",
    "    def best_split(self,data,num_of_iter):\n",
    "\n",
    "        best_split = {\"index\":-1,\"info_gain\":-1,\"left_data\":[],\"right_data\":[],\"treshold\":0}\n",
    "        index = -1\n",
    "        gain = -1\n",
    "        left_data = []\n",
    "        right_data = []\n",
    "        treshold = 0\n",
    "        max_info_gain = -float(\"inf\")\n",
    "        for i in range(data.shape[1]-1):\n",
    "            \n",
    "            column = data[:,i]\n",
    "            unq_column = np.unique(column)\n",
    "            sorted_unique = np.sort(unq_column)\n",
    "        \n",
    "            \n",
    "\n",
    "            if len(sorted_unique)>300:\n",
    "                jump = round(len(sorted_unique) / num_of_iter)\n",
    "                sampled_thresholds = sorted_unique[::jump]\n",
    "            else:\n",
    "                sampled_thresholds = sorted_unique\n",
    "\n",
    "            for j in sampled_thresholds:\n",
    "\n",
    "                left, right = self.split(data,i,j)\n",
    "                \n",
    "                if len(left) and len(right):\n",
    "                    information_gain = self.Information_Gain(data[:,-1],left[:,-1],right[:,-1])\n",
    "                    if information_gain > max_info_gain:\n",
    "\n",
    "                        index = i\n",
    "                        gain = information_gain\n",
    "                        left_data = left\n",
    "                        right_data = right\n",
    "                        treshold = j  \n",
    "                        max_info_gain = information_gain\n",
    "        \n",
    "        best_split[\"index\"] = index\n",
    "        best_split[\"info_gain\"] = gain\n",
    "        best_split[\"left_data\"] = left_data\n",
    "        best_split[\"right_data\"] = right_data\n",
    "        best_split[\"treshold\"] = treshold\n",
    "        \n",
    "        return best_split\n",
    "\n",
    "\n",
    "\n",
    "    def build_tree(self,data,curr_depth,num_of_iter):\n",
    "        \n",
    "\n",
    "        y_train = data[:,-1]\n",
    "\n",
    "        best_split = self.best_split(data,num_of_iter)\n",
    "\n",
    "        if curr_depth < self.max_depth:\n",
    "\n",
    "            if best_split[\"info_gain\"] > 0:\n",
    "                print(\"building the tree1\")\n",
    "                left_child = self.build_tree(best_split[\"left_data\"],curr_depth+1,num_of_iter)\n",
    "                right_child = self.build_tree(best_split[\"right_data\"],curr_depth+1,num_of_iter)\n",
    "                print(\"building the tree2\")\n",
    "                \n",
    "                return Node(left_child,right_child,best_split[\"index\"],best_split[\"treshold\"],best_split[\"info_gain\"])\n",
    "        \n",
    "        value_of_node = self.find_max_occuring_label(y_train)\n",
    "        print(\"building the tree\")\n",
    "        return Node(predicted_value=value_of_node)\n",
    "        \n",
    "    \n",
    "    def find_max_occuring_label(self,y):\n",
    "        return max(set(y), key=list(y).count)\n",
    "        \n",
    "\n",
    "    def predict_single(self,x_row,node):\n",
    "\n",
    "        if node.predicted_value >=0:\n",
    "            return node.predicted_value\n",
    "        \n",
    "        threshold= node.threshold\n",
    "        index_of_prmt = node.feature_index\n",
    "        if x_row[index_of_prmt] <= threshold:\n",
    "            return self.predict_single(x_row,node.left_child)\n",
    "        else:\n",
    "            return self.predict_single(x_row,node.right_child)\n",
    "\n",
    "\n",
    "\n",
    "    def test_data(self,x_test,y_test,root_node):\n",
    "\n",
    "        accuracy = 0\n",
    "        for i in range(len(x_test)):\n",
    "\n",
    "            if self.predict_single(x_test[i],root_node) == y_test[i]:\n",
    "                accuracy += 1\n",
    "        \n",
    "        return (accuracy * 100) / (len(x_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def print_tree(node, depth=0):\n",
    "\n",
    "    if node is None:\n",
    "        return\n",
    "    \n",
    "    indent = \"    \" * depth  # 4 spaces per depth level for indentation\n",
    "    \n",
    "    if node.predicted_value is not None:\n",
    "        # Leaf node\n",
    "        print(f\"{indent}Leaf: Predict = {node.predicted_value}\")\n",
    "    else:\n",
    "        # Internal node\n",
    "        print(f\"{indent}Node: Feature {node.feature_index}, Threshold {node.threshold}, Info Gain {node.information_gain:.4f}\")\n",
    "        # Recursively print the left and right subtrees\n",
    "        print_tree(node.left_child, depth + 1)\n",
    "        print_tree(node.right_child, depth + 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "\n",
    "data_train,x_test,y_test = data_prepration(\"Spotify_Features.csv\",test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "decision_tree = DecisionTree(4)\n",
    "\n",
    "root = decision_tree.build_tree(data_train,curr_depth=0,num_of_iter=100)\n",
    "print_tree(root,0)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mdecision_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy = \u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[46], line 194\u001b[0m, in \u001b[0;36mDecisionTree.test_data\u001b[0;34m(self, x_test, y_test, root_node)\u001b[0m\n\u001b[1;32m    191\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x_test)):\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mroot_node\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m y_test[i]:\n\u001b[1;32m    195\u001b[0m         accuracy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (accuracy \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mlen\u001b[39m(x_test))\n",
      "Cell \u001b[0;32mIn[46], line 177\u001b[0m, in \u001b[0;36mDecisionTree.predict_single\u001b[0;34m(self, x_row, node)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_single\u001b[39m(\u001b[38;5;28mself\u001b[39m,x_row,node):\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredicted_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m:\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mpredicted_value\n\u001b[1;32m    180\u001b[0m     threshold\u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mthreshold\n",
      "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "accuracy = decision_tree.test_data(x_test,y_test,root)\n",
    "\n",
    "print(\"Accuracy = \", accuracy,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
